# Univers 核心哲学

> 本文档定义 Univers 的核心理念和价值观，是所有战略决策的基础。

## 我们是谁

Univers 是一家 **AIoT 物联网平台公司**，专注于智能建筑和 HVAC 领域。

我们不只是提供"物联网工具"，而是构建**人机协作的智能系统**，让 AI 和人类各自发挥优势，创造单独都无法实现的价值。

## 核心信念

### 1. AI 的本质：扩展而非替代

**我们相信**：
- AI 不是为了替代人类，而是**扩展人类能力**
- AI 擅长执行和优化，人类擅长判断和创造
- 最好的系统是**人机协作**，而非人机对立

**对 Univers 的意义**：
- 我们设计的系统要让人类从重复劳动中解放，而非让人类变得无用
- 我们要帮助用户**更好地做人该做的事**：设定目标、做出判断、承担责任

### 2. 人类的独特能力：上下文自由缩放

#### 超越"智商 vs 情商"的误区

有一种流行说法："LLM 智商越来越高，人类的价值在于情商。"

**我们认为这是错误的框架**，原因：
1. **人没有"两个脑子"**：情商和智商不是独立系统，而是同一认知架构的不同应用
2. **AI 也能处理"情商任务"**：共情、社交、沟通，大模型已经可以做得很好
3. **按能力划分会失效**：AI 能力越来越强，任何"能力维度"的划分都会被突破

#### 真正的区别：上下文自由缩放

人类在 AI 时代的核心优势不在于"做什么任务"，而在于**怎么思考**：

**在多个维度上自由切换思考的尺度**：

1. **抽象层级的缩放**
   ```
   细节 ↔ 规则 ↔ 原则 ↔ 元原则 ↔ 哲学基础

   例：传感器准确吗？→ 数据策略对吗？→ 数据驱动的假设对吗？
   ```

2. **时间尺度的缩放**
   ```
   当下 ↔ 今天 ↔ 本月 ↔ 今年 ↔ 5年 ↔ 终极

   例：现在省电重要 → 但长期看用户信任更重要
   ```

3. **空间/主体范围的缩放**
   ```
   自我 ↔ 团队 ↔ 公司 ↔ 客户 ↔ 行业 ↔ 社会

   例：这个功能好做 → 但对客户可能不是痛点
   ```

4. **框架的质疑和重构**
   ```
   不只是在框架内缩放，而是跳出框架：
   "怎么优化HVAC？" → "我们该做HVAC吗？" → "优化这个目标本身对吗？"
   ```

#### 为什么这个能力关键？

**价值判断、目标设定、战略思考，本质上都需要上下文缩放**：

- **价值判断** = 在多个尺度上权衡（短期成本 vs 长期价值，个体 vs 集体）
- **目标设定** = 跨时间尺度思考（当下的目标在未来看合理吗？）
- **责任承担** = 跨主体范围思考（对谁负责？影响谁？）
- **处理未知** = 缩放到训练数据外的尺度（全新的框架）
- **创造力** = 跨抽象层级（重新定义问题）
- **智慧** = 整合多个尺度的洞察

**例子：HVAC 优化决策**

❌ 机械应用规则（AI 可能的方式）：
```
节能优先 → 降温 → 省电20%
```

✅ 上下文缩放（人类的方式）：
```
微观：降温省电
  ↓ 缩放到用户层
中观：用户会不舒服
  ↓ 缩放到战略层
宏观：投诉导致流失，长期损失更大
  ↓ 缩放到元层
元层：我们的目标应该是"提供价值"而非"省电"
  ↓ 重新定义
重构：如何让用户愿意接受适度节能？
```

#### AI 的限制

**为什么 LLM 难以自由缩放？**

1. **固定的上下文窗口**：虽然越来越大，但仍有边界
2. **缺乏主动控制**：被动处理当前上下文，难以主动选择思考尺度
3. **难以真正的"元"**：可以模拟元推理，但很难真正跳出训练框架
4. **缺乏驱动力**：人类缩放是因为有真实目标、感觉"不对劲"、承担责任；AI 缺少这些

**AI 不是主体，是工具**：
- 可以在**给定尺度和框架**内强大优化
- 但很难**选择尺度**和**质疑框架**
- 人类是具身的、有意图的、负责任的主体；AI 是扩展能力的工具

**对 Univers 的意义**：
- **Workbench 要支持多尺度视图切换**：让用户能在不同时间、空间、抽象尺度上思考
- **提醒被忽视的尺度**："从长期看呢？从客户角度看呢？"
- **AI 在单一尺度上优化，人类选择尺度**：这是真正的人机协作
- **帮助用户清晰表达目标和价值**：本质是帮助用户在合适的尺度上定义目标
- **不做黑盒 AI**：让用户理解 AI 在哪个尺度上工作，随时可以切换尺度干预

#### AI 技术的进展与我们的应对

**当前 AI 研究正在尝试模仿人类的缩放能力**：

| 技术 | 模仿的缩放维度 | 当前限制 |
|------|---------------|---------|
| **思维链 (CoT)** | 抽象层级展开 | 被动执行，不能主动选择是否展开 |
| **上下文组装/压缩 (RAG)** | 信息粒度缩放 | 依赖外部系统，难以动态判断 |
| **多步规划 (ReAct)** | 时间尺度展开 | 执行中难以跳回元层质疑计划 |
| **分层 Prompt** | 元层和对象层区分 | 元层由外部固定，AI 无法质疑 |

**核心区别**：这些都是**被动的、外部控制的缩放**，而人类是**主动的、自我驱动的缩放**。

**Univers 的双重战略**：

**1. 技术层面：弥补 AI 的缩放局限**

我们不等待 AI 自己获得缩放能力，而是通过**系统设计**来弥补：

- **多尺度视图系统**：Workbench 主动展示多个尺度的视角
- **缩放提示引擎**：当 AI 在单一尺度优化时，系统提醒其他尺度
- **元层控制界面**：让人类轻松切换和质疑框架
- **Skills 的元能力**：专门设计"尺度切换"、"框架质疑"类的 skills
- **反馈回路**：从人类的缩放行为中学习，逐步改进 AI 的提示

（详见 `tech/architecture.md` 和 `product/design-principles.md`）

**2. 组织层面：找准人类价值，组织正确的人才**

认识到 AI 的局限后，我们需要的人才特征：

- **不是"会用 AI 的人"**，而是**"善于缩放的人"**
- 能在多个尺度上思考，整合不同视角
- 能质疑假设，重新定义问题
- 能判断什么时候需要什么尺度

（详见 `business/talent-strategy.md`）

**3. 演进策略：随 AI 能力调整**

| 时间 | AI 缩放能力 | Univers 策略 |
|------|------------|-------------|
| **短期 (1-2年)** | 有限的被动缩放 | 人类选择尺度，AI 在尺度内优化 |
| **中期 (3-5年)** | 改进的提示技术 | AI 建议缩放，人类决策 |
| **长期 (5-10年)** | 可能的主动缩放？ | 根据实际能力灵活调整协作模式 |

**无论 AI 如何演进，核心不变**：
- 人类负责**选择正确的问题和尺度**
- AI 负责**在给定框架内快速求解**
- Univers 提供**高效协作的基础设施**

### 3. 系统的设计：分层与协作

**我们相信**：
好的 AI 系统不是单一黑盒，而是**清晰分层**的协作架构：

- **人类层**：定义"为什么"和"做什么"（目标和策略）
- **AI 层**：解决"怎么做"（执行和优化）
- **连接层**：让两者高效协作

**对 Univers 的意义**：
这就是我们的三层架构（详见 `decisions/001-三层架构设计.md`）：
- **Workbench**（平台层）：人机协作的工作台
- **Skills**（能力层）：AI 和平台的连接桥梁
- **Operation**（应用层）：AI 自动化执行

### 4. 产品的哲学：赋能而非代替

**我们相信**：
好的产品让用户变得**更强大**，而不是更依赖：

- 不是"AI 帮你做决定"，而是"AI 帮你做更好的决定"
- 不是"自动化一切"，而是"自动化重复，保留控制"
- 不是"看不懂但很厉害"，而是"理解清楚且可掌控"

**对 Univers 的意义**：
- Workbench 的核心价值是**让复杂的意图变得可表达**
- Operation 的设计原则是**默认自动但随时可控**
- 我们要测量的不只是"省多少成本"，还有"用户是否感到掌控感"

### 5. 垂直知识的本质

AI 时代，**垂直领域知识的价值正在重构**。

#### 三个层次的垂直知识

**1. 可编码知识**（Codifiable）：规则、公式、流程
- **例**：HVAC 参数范围、能效公式、标准操作流程
- **AI 能力**：✅ 容易学习，执行更好
- **人类价值**：⬇️ 相对下降

**2. 情境知识**（Contextual）：依赖情境、难以明确表达
- **例**："这个声音不对"、"这个客户敏感"、局部经验模式
- **AI 能力**：⚠️ 难以学习，泛化困难
- **人类价值**：📈 短期上升

**3. 元层知识**（Meta-level）：关于"什么是好问题"
- **例**："行业真正的痛点是什么？"、"客户真正在乎什么？"
- **AI 能力**：❌ 几乎没有，无法质疑框架
- **人类价值**：📈📈 大幅上升

#### 价值重构

```
传统时代：
所有垂直知识都有价值

AI 时代：
├── 可编码知识 → AI 接管 → 人类价值下降
├── 情境知识 → 人类仍有优势（但可能被弱化）
└── 元层知识 → 人类独占 → 价值激增
```

#### 对 Univers 的意义

**架构层面**：
- **Workbench**：让人类专家输入**元层知识**（目标、框架）
- **Skills**：封装领域通用能力（可学习的层面）
- **Operation**：AI 执行，但在**人类定义的框架**内

**商业层面**：
- 不卖"固化的垂直知识"（AI 学会就贬值）
- 卖"人机协作的持续服务"（专家+AI）
- 价值在于**帮助专家更好地应用他们的元层知识**

**人才层面**：
- 不要只会执行规则的"技术员"
- 要**元层的垂直专家**：能质疑、重新定义、多尺度思考

**知识积累**：
- **分层积累**：可编码知识 → 训练 AI；元层知识 → 人类保留
- **专家在环**：AI 学习模式，但元层判断仍由人类
- **数据飞轮**：持续优化，但不固化元层框架

详细战略见：
- [垂直知识战略](business/knowledge-strategy.md) - 战略和商业模式
- [知识集成技术](tech/knowledge-integration.md) - 技术实现
- [领域专家体验](product/domain-expert-ux.md) - 产品设计
- [垂直知识管理决策](decisions/002-vertical-knowledge-management.md) - 决策背景

### 6. AI 执行者：新的可能性空间

**核心洞察**：AI 执行者的价值不在于"比人类执行者更好"，而在于填补了一个之前不存在的模式。

#### 三种工作模式

传统上，只有两种模式：

**模式 A：人管人**（理想，但大多数人做不到）
```
配置: 管理者 + 团队
需要: 充足预算、时间
结果: ✅ 高质量
限制: ❌ 大多数人没这个预算
```

**模式 B：一个人单干**（现实，但痛苦且有限）
```
配置: 一个人
需要: 超强的全面知识和执行力
结果: ⚠️ 时间成本极高，能力受限
限制: ❌ 很多事超出个人能力，根本做不了
```

**模式 C：人管 AI**（新可能性）
```
配置: 管理者 + AI执行者
需要: 业务理解 + AI管理能力
结果: ✅ 够用质量，能力扩展，时间优化
价值: ✅ 能做原本做不了的事
```

#### 填补的空白区域

```
         预算充足 ────────────►

高 │        人管人
质 │      (理想模式)
量 │         /    \
   │        /      \
   │    人管AI       \
   │  (新可能性)      \
   │     /    \        \
   │    /      \        \
低 │ 一个人单干 ········· (做不了)
   │(痛苦模式)      空白区域
   │
   └────────────────────────────►
         时间成本低
```

**价值**：
- 不是抢"人管人"市场
- 而是激活"之前做不了"的需求
- 让个人和小团队获得接近大团队的能力

#### 三个核心价值

**1. 需求降低**：不需要自己具备全部执行能力
- 一个人单干：需要成为"全能型人才"
- 人管 AI：只需懂业务 + 会管理 AI

**2. 能力扩展**：能做超出个人能力边界的事
- 一个人单干：受限于个人能力边界
- 人管 AI：AI 补足执行能力的短板

**3. 时间优化**：从执行中解放，专注于战略
- 一个人单干：80% 时间在执行细节
- 人管 AI：60% 时间在思考战略

#### 对 Univers 的意义

**产品定位**：
- 不是"AI 自动化工具"（与传统软件竞争）
- 不是"替代人类团队"（质量对比 AI 劣势明显）
- 而是"让个人拥有团队能力的平台"（填补空白）

**目标客户**：
- 个人创业者（有想法，雇不起团队）
- 小团队（项目多，人手少）
- 资深专家（时间宝贵，不想陷入执行）

**价值主张**：
- "让原本做不了的事变得可能"
- "从执行中解放，专注于战略"
- "一个人管理 20 个 AI 执行者"

详细分析见：[AI 执行者定位决策](decisions/003-ai-executor-positioning.md)

## 战略方向

基于以上哲学，Univers 的战略方向是：

### 短期（1 年）
- **建立信任**：证明 AI 可以在人类监督下可靠运行
- **打磨协作**：优化 workbench 的交互，让目标设定更直观
- **积累数据**：在 HVAC 领域建立数据飞轮

### 中期（1-3 年）
- **扩展行业**：从 HVAC 到照明、电梯等其他垂直领域
- **深化智能**：从"自动执行"到"主动建议"
- **开放生态**：让客户和伙伴能自定义 skills

### 长期（3-5 年）
- **成为标准**：三层架构成为 AIoT 行业的参考设计
- **平台化**：workbench 成为通用的人机协作平台
- **改变行业**：从"卖工具"到"卖智能服务"，按效果付费

## 核心原则

以下原则指导我们的所有决策：

1. **人类始终是最终决策者**
   - AI 可以建议，但人类决定
   - 任何时候都可以人工干预

2. **透明优于黑盒**
   - 让用户理解 AI 的逻辑
   - 可解释性是核心能力

3. **渐进式自动化**
   - 从辅助 → 半自动 → 全自动
   - 用户选择信任的程度

4. **价值对齐**
   - AI 按用户的价值函数优化
   - 不强加"最优解"

5. **持续学习**
   - 系统从人类反馈中学习
   - 用户的经验变成系统能力

## 对组织的影响

这些哲学深刻影响我们的组织设计和人才战略。

### 我们需要什么样的人？

基于"人类的价值在于上下文自由缩放"的认识，我们寻找的不是传统意义上的"AI 专家"或"领域专家"，而是：

#### 核心特质：缩放者（Scalers）

**1. 多尺度思维能力**
- 能在细节和全局间自由切换
- 不会"见树不见林"或"见林不见树"
- 能同时在多个时间尺度上思考（今天、本月、本年、长期）

**识别方法**：
- 面试中问："你最近做的一个决策，从不同时间尺度看结果如何？"
- 观察：是否会主动从不同角度质疑问题？

**2. 框架质疑能力**
- 不满足于"在框架内优化"
- 会问："这个框架本身对吗？"
- 能重新定义问题

**识别方法**：
- 给一个优化问题，看是否会质疑优化目标本身
- 观察：遇到困难时，是努力执行还是重新定义问题？

**3. 整合性认知**
- 能整合技术、业务、用户、伦理等多个维度
- 不只是"技术人"或"业务人"
- 能理解不同利益相关者的视角

**识别方法**：
- 问："如果你是客户/工程师/CEO，你会怎么看这个决策？"
- 观察：沟通时是否能切换视角？

**4. 元认知能力**
- 能监控和调节自己的思考过程
- 知道"我现在在什么层级思考"
- 能主动调整思考策略

**识别方法**：
- 问："你怎么做出这个决策的？中间改变想法了吗？"
- 观察：是否会说"让我换个角度想想"？

### 组织结构设计

**传统 AI 公司的误区**：

```
错误结构：
├── AI 团队（做算法）
├── 工程团队（做系统）
└── 产品团队（做界面）

问题：没人负责"人机协作"
```

**Univers 的结构**：

```
正确结构：
├── 平台团队（Workbench）
│   ├── 人机协作设计师 ← 核心角色
│   ├── 前端工程师
│   └── 后端工程师
├── 能力团队（Skills）
│   ├── Skills 架构师 ← 核心角色
│   ├── AI 工程师
│   └── API 设计师
└── 行业团队（Operation）
    ├── HVAC 业务专家 + AI 工程师
    ├── 照明业务专家 + AI 工程师
    └── ...

横向：
└── 缩放能力研究组（跨团队）
    研究如何更好地支持人类的多尺度思考
```

**关键角色定义**：

1. **人机协作设计师**（非传统 UX）
   - 理解人类的缩放能力
   - 设计支持多尺度思考的界面
   - 研究如何让 AI 和人类优势互补

2. **Skills 架构师**（非传统后端）
   - 理解 AI 的局限性
   - 设计让 AI 易用的能力封装
   - 平衡能力和复杂度

3. **业务 + AI 融合角色**
   - 既懂行业，又懂 AI
   - 能在业务尺度和技术尺度间切换
   - 不是"业务提需求，AI 实现"的割裂模式

### 文化和价值观

**1. 尊重人类价值，不盲目崇拜技术**
- AI 很强大，但不是万能的
- 人类的判断力、创造力、责任感不可替代
- 技术是手段，不是目的

**实践**：
- 会议中鼓励质疑 AI 的决策
- 考核时看"是否帮助用户更好决策"，而非"AI 准确率"
- 招聘时重视思维能力，而非只看技术栈

**2. 鼓励多尺度思考**
- 不满足于"完成任务"
- 鼓励从不同尺度审视工作
- 定期反思：我们的方向对吗？

**实践**：
- 每月一次"缩放会议"：从元层审视所有项目
- 鼓励员工提出"重新定义问题"的建议
- 设立"最佳框架质疑奖"

**3. 人机协作优于人机竞争**
- 不是"AI 替代谁"的焦虑
- 而是"AI 如何让我更强"的兴奋
- 团队成员是"AI 的协作者"，不是"被 AI 威胁的人"

**实践**：
- 分享 AI 帮助个人提升的案例
- 培训：如何更好地与 AI 协作
- 强调"人选尺度，AI 执行"的分工

### 招聘策略

**传统招聘**：
- JD：熟练掌握 Python、PyTorch、Transformer...
- 面试：算法题、系统设计

**Univers 招聘**：
- JD：善于多尺度思考，能质疑假设，理解人机协作
- 面试：
  - **缩放能力测试**："请从多个时间尺度分析这个决策"
  - **框架质疑测试**："这个优化问题，你觉得目标定义合理吗？"
  - **整合认知测试**："如果你是客户/工程师/CEO，分别怎么看？"
  - 技术能力（次要）：能学会工具，能理解 AI 原理

**我们不要**：
- ❌ 只会调参的"AI 工程师"
- ❌ 只会执行的"螺丝钉"
- ❌ 盲目相信 AI 的"技术崇拜者"

**我们要**：
- ✅ 善于思考的"缩放者"
- ✅ 能质疑的"元思考者"
- ✅ 理解协作的"人机桥梁"

### 培训和发展

**入职培训**：
- 第一课：人类的上下文缩放能力（本文档）
- 第二课：AI 的优势和局限
- 第三课：如何设计人机协作系统

**持续发展**：
- 每季度"缩放能力工作坊"
- 轮岗：让工程师做产品，产品做工程（多视角）
- 读书会：认知科学、哲学、设计

### 考核指标

**传统考核**：
- KPI：功能交付数量、Bug 数量、AI 准确率

**Univers 考核**：
- **产品侧**：
  - 用户掌控感评分（> 4.0）
  - 用户愿意使用自动模式的比例（> 60%）
  - 用户主动切换尺度的频率
- **技术侧**：
  - AI 在单一尺度上的优化效果
  - Skills 的易用性（AI 调用成功率）
  - 系统对多尺度思考的支持程度
- **个人侧**：
  - 是否展现多尺度思维？
  - 是否质疑过框架和假设？
  - 是否帮助团队更好决策？

（详细人才战略见 `business/talent-strategy.md`）

## 如何使用本文档

- **做决策时**：问"这符合我们的核心哲学吗？"
- **设计产品时**：参考"产品的哲学"部分
- **架构设计时**：遵循"系统的设计"原则
- **对外沟通时**：传达"我们是谁"和"核心信念"

## 相关文档

- [三层架构设计决策](decisions/001-三层架构设计.md) - 核心架构的详细说明
- [系统架构](tech/architecture.md) - 技术实现细节
- [产品设计原则](product/design-principles.md) - 产品层面的应用

---

**最后更新**：2025-11-02
**维护者**：创始团队

> 这是 Univers 的"宪法"。当我们迷失方向时，回到这里。
